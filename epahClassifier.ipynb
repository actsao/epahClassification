{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "237fcedd-67d0-49d2-b881-9481f32723f5",
   "metadata": {},
   "source": [
    "### Import the dataset with labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "791e4bd7-d3bd-46c4-a76b-21315a6d1a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pywt\n",
    "import random\n",
    "from scipy.io import loadmat\n",
    "\n",
    "from tsfresh import extract_relevant_features\n",
    "\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e312eea8-4cb4-4d3f-8ec9-e641110775b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# files = [f'waveforms/{f}' for f in os.listdir('waveforms') if 'HG8707' in f or 'HJ3311' in f]\n",
    "# files = [f'waveforms/{f}' for f in os.listdir('waveforms') if 'clean' in f and 'diast' not in f and 'trended' not in f]\n",
    "\n",
    "class epahClassifier():\n",
    "    def __init__(self, waveforms=None, labels=None):\n",
    "        self.waveforms = waveforms\n",
    "        self.labels = labels\n",
    "    \n",
    "    def load_waveforms_from_files(self, files):\n",
    "        # Load time series into DataFrame\n",
    "        df_list = []\n",
    "        for file in files:\n",
    "            # Load ECG data from the downloaded MATLAB file\n",
    "            mat = loadmat(file)\n",
    "            file_id = file.split('.')[0]\n",
    "            file_id = file_id.split('/')[-1]\n",
    "            \n",
    "            # For now, there are two types of files\n",
    "            # - Files ending in '_000' only contain ONE waveform\n",
    "            # - Files containing 'clean' may contain MULTIPLE waveforms\n",
    "            if 'wave' in mat:\n",
    "                # Note: Each file only contains ONE waveform!\n",
    "                wave = mat['wave'][0][0][13][3]\n",
    "\n",
    "                for i, x in enumerate(wave):\n",
    "                    df_dict = {\n",
    "                        'id':      file_id,\n",
    "                        'time':    i,\n",
    "                        'value':   wave[i],\n",
    "                    }\n",
    "\n",
    "                    df_list.append(df_dict)\n",
    "                    \n",
    "            elif 'savecleanforms' in mat:\n",
    "                # Note: Each file may contain multiple waveforms!\n",
    "                waves = mat['savecleanforms']['wave']\n",
    "                \n",
    "                # Create entries for each waveform in the mat file\n",
    "                for wave_num, wave in enumerate(waves.item()[0]):\n",
    "                    wave = wave[0]\n",
    "                    \n",
    "                    for i, x in enumerate(wave):\n",
    "                        df_dict = {\n",
    "                            'id':      f'{file_id}_{wave_num}',\n",
    "                            'time':    i,\n",
    "                            'value':   wave[i],\n",
    "                        }\n",
    "                        \n",
    "                        df_list.append(df_dict)\n",
    "\n",
    "        self.waveforms = pd.DataFrame(df_list)\n",
    "    \n",
    "    def load_labels_from_files(self, files):\n",
    "        # Load labels into Data Series\n",
    "        labels_dict = {}\n",
    "        ind = []\n",
    "        for file in files:\n",
    "            file_id = file.split('_')[0]\n",
    "            \n",
    "            if mat.has_key('wave'):\n",
    "                # Note: Each file only contains ONE waveform!\n",
    "                labels_dict[file_id] = int(data[0] % 2)\n",
    "                ind.append(file_id)\n",
    "                \n",
    "            elif mat.has_key('savecleanforms'):\n",
    "                # Note: Each file may contain multiple waveforms!\n",
    "                labels_dict[file_id] = int(data[0] % 2)\n",
    "                ind.append(file_id)\n",
    "\n",
    "        self.labels = pd.Series(labels_dict, index=ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4b32b228-6734-492d-b8dd-5f02961b6d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Size: 25\n",
      "# Waveforms: 156\n"
     ]
    }
   ],
   "source": [
    "epah = epahClassifier()\n",
    "\n",
    "files_in_folder = [f'waveforms/{f}' for f in os.listdir('waveforms') if 'clean' in f and 'diast' not in f and 'trended' not in f and 'EL1030' not in f]\n",
    "# files_in_folder = [f'waveforms/{f}' for f in os.listdir('waveforms') if 'clean' in f and'diast' not in f and 'trended' not in f]\n",
    "\n",
    "df_labels = pd.read_csv('labels.csv')\n",
    "df_labels['Filename'] = df_labels['Filename'].str.strip()\n",
    "df_labels = df_labels.set_index(['Filename'])\n",
    "df_labels['File_Exists'] = [any(filename.split('_')[0] in f for f in files_in_folder) for filename in df_labels.index]\n",
    "df_labels['RHC_and_Exists'] = ~df_labels['RHC_or_CPET'] & df_labels['File_Exists']\n",
    "df_labels['Label'] = df_labels['Source'].map({'control': 0, 'pah': 1, 'epah': 2})\n",
    "\n",
    "files = [f'waveforms/{f.strip()}cleanforms.mat' for f in df_labels[df_labels['RHC_and_Exists']].index]\n",
    "\n",
    "epah.load_waveforms_from_files(files)\n",
    "\n",
    "print(f'Data Size: {len(files)}')\n",
    "\n",
    "print(f'# Waveforms: {len(epah.waveforms.id.unique())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c72c4a6e-b98c-46bb-aa3d-ecfba049af58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    65\n",
      "1    61\n",
      "0    30\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "id_list = list(epah.waveforms['id'])\n",
    "\n",
    "labels_dict = {}\n",
    "for file_id in id_list:\n",
    "    labels_dict[file_id] = df_labels.loc[file_id.split('clean')[0]]['Label']\n",
    "\n",
    "epah.labels = pd.Series(labels_dict, index=list(labels_dict.keys()))\n",
    "\n",
    "print(epah.labels.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "30f5637b-3e39-4196-bd9d-c142fd4155ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "waveforms = epah.waveforms['id'].unique()\n",
    "\n",
    "use_interp = True\n",
    "use_normalize = False\n",
    "use_standardize = True\n",
    "\n",
    "if use_interp:\n",
    "    df_list = []\n",
    "    for wave_id in waveforms:\n",
    "        id_mask = epah.waveforms['id'].str.contains(wave_id, regex=False)\n",
    "        wave = epah.waveforms[id_mask]['value']\n",
    "        wave_interp = np.interp(np.linspace(0, len(wave), 500), np.arange(0, len(wave)), wave)\n",
    "\n",
    "        for i, x in enumerate(wave_interp):\n",
    "            df_dict = {\n",
    "                'id':      wave_id,\n",
    "                'time':    i,\n",
    "                'value':   wave_interp[i],\n",
    "            }\n",
    "\n",
    "            df_list.append(df_dict)\n",
    "\n",
    "    epah.waveforms = pd.DataFrame(df_list)\n",
    "\n",
    "if use_normalize or use_standardize:\n",
    "    for wave_id in waveforms:\n",
    "        id_mask = epah.waveforms['id'].str.contains(wave_id, regex=False)\n",
    "        if use_normalize:\n",
    "            epah.waveforms.loc[id_mask, 'value_norm'] = (epah.waveforms[id_mask]['value'] - epah.waveforms[id_mask]['value'].min()) / (epah.waveforms[id_mask]['value'].max() - epah.waveforms[id_mask]['value'].min())\n",
    "        elif use_standardize:\n",
    "            epah.waveforms.loc[id_mask, 'value_norm'] = (epah.waveforms[id_mask]['value'] - epah.waveforms[id_mask]['value'].mean()) / epah.waveforms[id_mask]['value'].std()\n",
    "\n",
    "df_waveforms = epah.waveforms.copy()\n",
    "df_waveforms = df_waveforms.drop(columns=['value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f701a3c4-09f9-47f3-a099-493fc6ab4785",
   "metadata": {},
   "source": [
    "### Create Pipeline & Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "095a98fb-8083-471c-85bf-fd670c66ba8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from tsfresh.transformers import RelevantFeatureAugmenter\n",
    "from tsfresh.utilities.dataframe_functions import impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e4e710-acb5-4594-8ea5-f9850e12d740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classes:\n",
    "# 0: Control\n",
    "# 1: PAH\n",
    "# 2: EPAH\n",
    "\n",
    "# Remove Class\n",
    "# -1 -->  keep all 3 classes\n",
    "# 0  -->  PAH vs EPAH\n",
    "# 1  -->  Control vs EPAH\n",
    "# 2  -->  Control vs PAH\n",
    "class_remove = 2\n",
    "\n",
    "y = epah.labels[epah.labels != class_remove]\n",
    "\n",
    "X = pd.DataFrame(index=y.index)\n",
    "\n",
    "# Split data into train and test set\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "# Ensure even split between labels\n",
    "# FOR NOW, pick 2 patients randomly from each class\n",
    "pt_list = list(set(ind.split('_')[0] for ind in y.index))\n",
    "\n",
    "pt_labels = []\n",
    "for pt in pt_list:\n",
    "    label = y[[pt in ind for ind in y.index]][0]\n",
    "    weight = sum([pt in ind for ind in y.index])\n",
    "    \n",
    "    pt_labels.append({\n",
    "        'pt':     pt,\n",
    "        'label':  label,\n",
    "        'weight': weight,\n",
    "    })\n",
    "\n",
    "pt_df = pd.DataFrame(pt_labels)\n",
    "\n",
    "if class_remove == 0:\n",
    "    pt_test = pd.concat([pt_df[pt_df['label'] == 1].sample(n=3),\n",
    "                         pt_df[pt_df['label'] == 2].sample(n=3)])\n",
    "elif class_remove == 1:\n",
    "    pt_test = pd.concat([pt_df[pt_df['label'] == 0].sample(n=2),\n",
    "                         pt_df[pt_df['label'] == 2].sample(n=3)])\n",
    "elif class_remove == 2:\n",
    "    pt_test = pd.concat([pt_df[pt_df['label'] == 0].sample(n=2),\n",
    "                         pt_df[pt_df['label'] == 1].sample(n=3),])\n",
    "else:\n",
    "    pt_test = pd.concat([pt_df[pt_df['label'] == 0].sample(n=2),\n",
    "                         pt_df[pt_df['label'] == 1].sample(n=3),\n",
    "                         pt_df[pt_df['label'] == 2].sample(n=3)])\n",
    "\n",
    "display(pt_test)\n",
    "\n",
    "y_train = y[[all(pt not in ind for pt in pt_test['pt']) for ind in y.index]]\n",
    "X_train = X[[all(pt not in ind for pt in pt_test['pt']) for ind in X.index]]\n",
    "y_test = y[[any(pt in ind for pt in pt_test['pt']) for ind in y.index]]\n",
    "X_test = X[[any(pt in ind for pt in pt_test['pt']) for ind in X.index]]\n",
    "\n",
    "print(f'Training Split: {len(y_train)}')\n",
    "print(f'Testing  Split: {len(y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1aed61-b395-425b-a7a0-f5a3e53075fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppl = Pipeline([\n",
    "        ('augmenter', RelevantFeatureAugmenter(column_id='id', column_sort='time')),\n",
    "        ('classifier', RandomForestClassifier())\n",
    "      ])\n",
    "\n",
    "ppl.set_params(augmenter__timeseries_container=df_waveforms[df_waveforms['id'].isin(y.index)])\n",
    "\n",
    "ppl.fit(X_train, y_train)\n",
    "\n",
    "y_pred = ppl.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acb373f-2e9f-4db0-8d60-c17460080d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_roc_curve\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plot_roc_curve(ppl, X_test, y_test, ax=ax)\n",
    "ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "        label='Chance', alpha=.6)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5dd2a3-9ca0-4c96-9e17-217e8a2ec4d7",
   "metadata": {},
   "source": [
    "### Calculate Relevant Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9e8d93a3-055d-4e7c-927a-97f4d9ba7cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsfresh import extract_features\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "from tsfresh.feature_selection.relevance import calculate_relevance_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0041fe9b-4bc9-4740-9cfd-736292292929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Class\n",
    "# -1 -->  keep all 3 classes\n",
    "# 0  -->  PAH vs EPAH\n",
    "# 1  -->  Control vs EPAH\n",
    "# 2  -->  Control vs PAH\n",
    "\n",
    "classes = [0, 1, 2]\n",
    "\n",
    "for class_remove in classes:\n",
    "    y = epah.labels[epah.labels != class_remove]\n",
    "\n",
    "    # Ensure even split between labels\n",
    "    # FOR NOW, pick 2 patients randomly from each class\n",
    "    pt_list = list(set(ind.split('_')[0] for ind in y.index))\n",
    "\n",
    "    relevant_list = []\n",
    "    relevant_dict = {}\n",
    "    num_trials = 10\n",
    "    for i in np.arange(0, num_trials):\n",
    "        pt_labels = []\n",
    "        for pt in pt_list:\n",
    "            label = y[[pt in ind for ind in y.index]][0]\n",
    "            weight = sum([pt in ind for ind in y.index])\n",
    "\n",
    "            pt_labels.append({\n",
    "                'pt':     pt,\n",
    "                'label':  label,\n",
    "                'weight': weight,\n",
    "            })\n",
    "\n",
    "        pt_df = pd.DataFrame(pt_labels)\n",
    "\n",
    "        if class_remove == 0:\n",
    "            pt_test = pd.concat([pt_df[pt_df['label'] == 1].sample(n=3),\n",
    "                                 pt_df[pt_df['label'] == 2].sample(n=3)])\n",
    "        elif class_remove == 1:\n",
    "            pt_test = pd.concat([pt_df[pt_df['label'] == 0].sample(n=2),\n",
    "                                 pt_df[pt_df['label'] == 2].sample(n=3)])\n",
    "        elif class_remove == 2:\n",
    "            pt_test = pd.concat([pt_df[pt_df['label'] == 0].sample(n=2),\n",
    "                                 pt_df[pt_df['label'] == 1].sample(n=3),])\n",
    "        else:\n",
    "            pt_test = pd.concat([pt_df[pt_df['label'] == 0].sample(n=2),\n",
    "                                 pt_df[pt_df['label'] == 1].sample(n=3),\n",
    "                                 pt_df[pt_df['label'] == 2].sample(n=3)])\n",
    "\n",
    "    #     display(pt_test)\n",
    "\n",
    "        y_train = y[[all(pt not in ind for pt in pt_test['pt']) for ind in y.index]]\n",
    "        # X_train = X[[all(pt not in ind for pt in pt_test['pt']) for ind in X.index]]\n",
    "        y_test = y[[any(pt in ind for pt in pt_test['pt']) for ind in y.index]]\n",
    "        # X_test = X[[any(pt in ind for pt in pt_test['pt']) for ind in X.index]]\n",
    "\n",
    "    #     print(f'Training Split: {len(y_train)}')\n",
    "    #     print(f'Testing  Split: {len(y_test)}')\n",
    "\n",
    "        extracted_features = extract_features(epah.waveforms[epah.waveforms['id'].isin(y_train.index)], column_id='id', column_sort='time', column_value='value_norm')\n",
    "        impute(extracted_features)\n",
    "        df_relevance_table = calculate_relevance_table(extracted_features, y_train)\n",
    "\n",
    "        for key, value in df_relevance_table[df_relevance_table['relevant']]['p_value'].items():\n",
    "            relevant_dict.setdefault(key, []).append(value)\n",
    "\n",
    "    with open(f'allRelevant_dict_{class_remove}_standardized.csv', 'w') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Feature', 'Mean P Value', 'P Values', 'Num_Relevant(10)'])\n",
    "        for key, value in sorted(list(relevant_dict.items())):\n",
    "            writer.writerow([key, np.mean(value), value, len(value)])\n",
    "\n",
    "    for key, value in list(relevant_dict.items()):\n",
    "        if len(value) < num_trials:\n",
    "            del relevant_dict[key]\n",
    "\n",
    "    with open(f'relevant_dict_{class_remove}_standardized.csv', 'w') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Feature', 'Mean P Value', 'P Values'])\n",
    "        for key, value in sorted(list(relevant_dict.items())):\n",
    "            writer.writerow([key, np.mean(value), value])\n",
    "\n",
    "    sorted(list(relevant_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9fb509bb-a302-48e3-a0a7-fc77804e74a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████| 26/26 [00:16<00:00,  1.57it/s]\n",
      "C:\\Users\\andre\\miniconda3\\envs\\epahClassification\\lib\\site-packages\\tsfresh\\utilities\\dataframe_functions.py:171: RuntimeWarning: The columns ['value_norm__query_similarity_count__query_None__threshold_0.0'] did not have any finite values. Filling with zeros.\n",
      "  warnings.warn(\"The columns {} did not have any finite values. Filling with zeros.\".format(\n"
     ]
    }
   ],
   "source": [
    "# Calculate ALL features for ALL waveforms + Save to CSV\n",
    "extracted_features = extract_features(epah.waveforms, column_id='id', column_sort='time', column_value='value')\n",
    "impute(extracted_features)\n",
    "\n",
    "extracted_features_labelled = extracted_features.copy()\n",
    "\n",
    "for index, value in df_labels['Source'].items():\n",
    "    extracted_features_labelled.loc[extracted_features_labelled.index.str.contains(index), 'label'] = value\n",
    "\n",
    "extracted_features_labelled = extracted_features_labelled[['label'] + list(extracted_features.columns.values)]\n",
    "\n",
    "extracted_features_labelled.to_csv('calculated_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "637865dd-f921-460d-86f4-c86d1a469cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████| 26/26 [00:07<00:00,  3.32it/s]\n",
      "C:\\Users\\andre\\miniconda3\\envs\\epahClassification\\lib\\site-packages\\tsfresh\\utilities\\dataframe_functions.py:171: RuntimeWarning: The columns ['value__query_similarity_count__query_None__threshold_0.0'] did not have any finite values. Filling with zeros.\n",
      "  warnings.warn(\"The columns {} did not have any finite values. Filling with zeros.\".format(\n"
     ]
    }
   ],
   "source": [
    "# Calculate ONLY RELEVANT features for ALL waveforms + Save to CSV\n",
    "extracted_features = extract_features(epah.waveforms, column_id='id', column_sort='time', column_value='value')\n",
    "impute(extracted_features)\n",
    "\n",
    "# Remove Class\n",
    "# -1 -->  keep all 3 classes\n",
    "# 0  -->  PAH vs EPAH\n",
    "# 1  -->  Control vs EPAH\n",
    "# 2  -->  Control vs PAH\n",
    "\n",
    "classes = [0, 1, 2]\n",
    "\n",
    "for class_remove in classes:\n",
    "    extracted_features_labelled = extracted_features.copy()\n",
    "\n",
    "    for index, value in df_labels['Source'].items():\n",
    "        extracted_features_labelled.loc[extracted_features_labelled.index.str.contains(index), 'label'] = value\n",
    "        \n",
    "    relevant_features = pd.read_csv(f'relevant_features/relevant_dict_{class_remove}.csv')\n",
    "    \n",
    "    extracted_features_labelled = extracted_features_labelled[['label'] + list(relevant_features['Feature'])]\n",
    "\n",
    "    extracted_features_labelled.to_csv(f'calculated_relevantFeatures_{class_remove}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ea8ea8-b34b-413e-be8b-d37e5efcdf36",
   "metadata": {},
   "source": [
    "### Create Images of Each Waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "48a372e3-a631-45c5-a4c6-c10a94848d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of raw values\n",
    "waves = epah.waveforms['id'].unique()\n",
    "\n",
    "for wave in waves:\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "    \n",
    "    label = df_labels.loc[wave.split('clean')[0]]['Source']\n",
    "    values = epah.waveforms[epah.waveforms['id'].str.contains(wave, regex=False)]['value_norm']\n",
    "    \n",
    "    ax.plot(np.arange(0, len(values)), values)\n",
    "    ax.set_title(f'{wave}  •  {label.upper()}  •  Mean: {values.mean():0.3f} ± {values.std():0.3f}', fontsize=14)\n",
    "    \n",
    "#     break\n",
    "    \n",
    "    fig.savefig(f'waveforms_images/standardized/waveforms/{wave}_image.jpg')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0805901c-1cc8-419b-ab7e-1428a669c4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of CWT of waveforms\n",
    "waves = epah.waveforms['id'].unique()\n",
    "\n",
    "for wave in waves:\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(7, 5))\n",
    "    \n",
    "    label = df_labels.loc[wave.split('clean')[0]]['Source']\n",
    "    values = epah.waveforms[epah.waveforms['id'].str.contains(wave, regex=False)]['value']\n",
    "    \n",
    "    num_steps = 256\n",
    "    scales = np.arange(1, num_steps+1)\n",
    "    wavelet_type = 'mexh'\n",
    "    coefs, freqs = pywt.cwt(values, scales, wavelet_type)\n",
    "    im = ax.imshow(coefs, cmap='coolwarm')\n",
    "    cb = plt.colorbar(im, ax=ax)\n",
    "    cb.set_label('Intensity', rotation=270)\n",
    "    ax.set_xlabel('Time')\n",
    "    ax.set_ylabel('Scale')\n",
    "    ax.set_title(f'{wave}  •  {label.upper()}', fontsize=14)\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    \n",
    "#     break\n",
    "    \n",
    "    fig.savefig(f'waveforms_images/standardized/cwt/{wavelet_type}/{wave}_image.jpg')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8a2b34-c2ed-4152-ad9d-b03455dc7c0a",
   "metadata": {},
   "source": [
    "### MISC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0db9801-a8f7-4c4d-9e01-effca604d8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edits a column in csv and resaves\n",
    "\n",
    "from ast import literal_eval\n",
    "\n",
    "filename = 'allRelevant_dict_0_standardized.csv'\n",
    "\n",
    "df = pd.read_csv(filename)\n",
    "\n",
    "df['P Values'] = df['P Values'].apply(literal_eval)\n",
    "df['Num_Relevant(10)'] = [len(x) for x in df['P Values']]\n",
    "\n",
    "df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080d2fa0-96e6-45d6-8a24-4e1b7763aca9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
